{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-19T09:33:35.414638Z",
     "start_time": "2025-08-19T09:33:27.747272Z"
    }
   },
   "source": [
    "from math import ceil\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from mimic.orm_create.mimiciv_v3_orm import Labels, Note, PreprocessedRevisedNote\n",
    "from sqlalchemy import create_engine, and_, func\n",
    "from torch_geometric.nn.conv import GATConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from sklearn import metrics\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "import os\n",
    "import gc\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "DIR_NAME = \"20250816_qwen32b_kgs_out\"#\"20250812_qwen_1_7b_kgs_out\" #\"20250810_qwen_14b_kgs_out\""
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\git\\KARDIA\\.venv\\Lib\\site-packages\\hyperopt\\atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:33:35.424087Z",
     "start_time": "2025-08-19T09:33:35.420896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_all_seeds(seed):\n",
    "    \"\"\"Set seeds for reproducibility .\"\"\"\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    return g\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    \"\"\"Set seed for DataLoader workers.\"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ],
   "id": "26ccfd8a423ad877",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:33:35.443565Z",
     "start_time": "2025-08-19T09:33:35.441146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_session():\n",
    "    DB_URI = \"postgresql://postgres:password@localhost:5432/mimicIV_v3\"\n",
    "    engine = create_engine(DB_URI)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "    return session"
   ],
   "id": "58e8e776ae2e08e8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:33:35.453375Z",
     "start_time": "2025-08-19T09:33:35.447621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.utils import add_self_loops\n",
    "import re\n",
    "def get_note(graph_dir):\n",
    "\tfile_name = f\"batched_notes/{graph_dir}.json\"\n",
    "\twith open(file_name, \"r\") as f:\n",
    "\t\tdata = json.load(f)\n",
    "\treturn data\n",
    "\n",
    "def get_edges(graph):\n",
    "    ## TODO Build up edge vocabulary in graph\n",
    "    entity_dict = {key: i for i, key in enumerate(graph[\"entities\"])}\n",
    "    edge_dict = {key: i for i, key in enumerate(graph[\"edges\"])}\n",
    "    edge_idx, edge_attr = [], []\n",
    "    for relation in graph[\"relations\"]:\n",
    "        src, rel, trg = relation\n",
    "        edge_idx.append((entity_dict[src], entity_dict[trg]))\n",
    "    edge_idx = np.array(edge_idx)\n",
    "    edge_idx = torch.from_numpy(edge_idx).type(torch.int64)\n",
    "    edge_idx = edge_idx.transpose(-1, 0)\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float32)\n",
    "    if edge_idx.ndim == 1:\n",
    "        edge_idx = torch.tensor([[], []], dtype=torch.long)\n",
    "    if edge_attr.ndim == 1:\n",
    "        edge_attr = torch.tensor([], dtype=torch.float)\n",
    "    return edge_idx, edge_attr\n",
    "\n",
    "def get_label(session, dir, note):\n",
    "    row_id = note[\"row_id\"]\n",
    "    label = session.query(Labels.label).where(Labels.row_id == row_id).one_or_none()\n",
    "    label = int(label[0])\n",
    "    label = torch.tensor([label], dtype=torch.float)\n",
    "    return label, row_id\n",
    "  \n",
    "def get_entities_list(graph):\n",
    "    graph[\"entities\"] = list(map(lambda e: e, graph[\"entities\"])) ## prevent nothing and use def. tokenizer -> Lets just map multiple tokens back to one word via sum of the tokenizer\n",
    "    entities_list = graph[\"entities\"]\n",
    "    return entities_list\n",
    "\n",
    "def add_readout_node(data):\n",
    "    data.x = torch.concatenate([data.x, torch.mean(data.x, dim = 0).unsqueeze(0)])\n",
    "    data.readout_mask = torch.zeros(data.x.shape[0], dtype=torch.bool)\n",
    "    data.readout_mask[-1] = 1\n",
    "    \"\"\"Connect all nodes in the KG to the last read-out node\"\"\"\n",
    "    new_src = torch.arange(data.x.shape[0])\n",
    "    new_trg = torch.ones_like(new_src)*(data.x.shape[0]- 1)\n",
    "    ## -1 and -1 represent mean that I dont want to add a self edge on the readout node, i.e., theoretically on attention heads from KG nodes can contribute to the read out node\n",
    "    readout_edges = torch.stack([new_src[:-1], new_trg[:-1]])\n",
    "    data.edge_index = torch.cat([data.edge_index, readout_edges], dim = -1)\n",
    "    #data.edge_attr = torch.cat([data.edge_attr, torch.ones((readout_edges.shape[-1], 768), dtype = torch.float)], dim = 0)\n",
    "    \n",
    "def create_graph(session, dir):\n",
    "    graph = json.load(open(f\"{DIR_NAME}/{dir}/graph.json\")) #json.load(open(os.path.join(\"revised_kgs\", dir, \"graph.json\"), \"r\"))\n",
    "    note = get_note(dir)\n",
    "    graph[\"entities\"] = list(set(graph[\"entities\"] + re.findall(r\"(?u)\\b\\w\\w+\\b\", note[\"text\"])))\n",
    "    if len(graph[\"entities\"]) == 0: return None\n",
    "    edge_index, _ = get_edges(graph)\n",
    "    y, row_id = get_label(session, dir, note)\n",
    "    x = torch.zeros(len(graph[\"entities\"]), 1, dtype=torch.float32)\n",
    "    entities_list = get_entities_list(graph)\n",
    "    edge_index = add_self_loops(edge_index)[0]\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=None, y=y, entities_list = entities_list, row_id= row_id, dir = dir)\n",
    "    add_readout_node(data)\n",
    "    gc.collect()\n",
    "    return data"
   ],
   "id": "37d3545ec3fffeed",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:33:35.459106Z",
     "start_time": "2025-08-19T09:33:35.456897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_valid_note_row_ids(session):\n",
    "    \"\"\"Necessary because in my prevoius filtering steps I didnt excluded them and KG creation is still running (dont want interrupt)\"\"\"\n",
    "    db_note_row_ids = session.query(PreprocessedRevisedNote.row_id).filter(and_(func.lower(PreprocessedRevisedNote.text).not_like(\"%sepsis%\"), func.lower(PreprocessedRevisedNote.text).not_like(\"%septic%\"), func.lower(PreprocessedRevisedNote.text).not_like(\"%shock%\"))).all()\n",
    "    db_note_row_ids = list(map(lambda n: n[0], db_note_row_ids))\n",
    "    return db_note_row_ids"
   ],
   "id": "1a5d2fbdbd683049",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T12:16:46.085090Z",
     "start_time": "2025-08-19T12:16:46.080859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_graphs():\n",
    "    data_graphs = []\n",
    "    session = get_session()\n",
    "    db_note_row_ids = get_valid_note_row_ids(session)\n",
    "    kg_dirs = os.listdir(DIR_NAME) #os.listdir(\"revised_kgs\")\n",
    "    kg_dirs = list(filter(lambda n: \".\" not in n, kg_dirs))\n",
    "    kg_dirs = list(map(int, kg_dirs))\n",
    "    kg_dirs.sort()\n",
    "    for dir in tqdm(kg_dirs[:30]):\n",
    "        note = get_note(dir)\n",
    "        if int(note[\"row_id\"]) not in db_note_row_ids: continue\n",
    "        data = create_graph(session, str(dir))\n",
    "        data_graphs.append(data)\n",
    "    session.close()\n",
    "    return data_graphs"
   ],
   "id": "eace8f9cf597b153",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T12:16:46.672303Z",
     "start_time": "2025-08-19T12:16:46.669310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_train_and_test_graphs():\n",
    "    data_graphs = get_graphs()\n",
    "    ## TODO Use time-based splits across all experiments\n",
    "    train_idx, test_idx = train_test_split(np.arange(len(data_graphs)), test_size=0.2, stratify=[data.y for data in data_graphs], random_state=42) #\n",
    "    \n",
    "    train_data = [data_graphs[idx] for idx in train_idx]\n",
    "    test_data = [data_graphs[idx] for idx in test_idx]\n",
    "    return train_data, test_data"
   ],
   "id": "ae93d0504c7f0d82",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T12:17:29.176365Z",
     "start_time": "2025-08-19T12:17:29.171303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_vectorized_train_and_test_graphs():\n",
    "    train_data, test_data = get_train_and_test_graphs()\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    print(\"Fit tokenizer\")\n",
    "    vectorizer.fit(list(map(lambda d: \"\\t\".join(d.entities_list), train_data)))\n",
    "    num_features = len(vectorizer.vocabulary_)\n",
    "\n",
    "    # Process both train and test datasets\n",
    "    os.makedirs(\"vectorized_graphs\", exist_ok = True)\n",
    "    for data_set_name, data_set in [(\"train\", train_data), (\"test\", test_data)]:\n",
    "        print(f\"Processing {data_set_name} set...\")\n",
    "        processed_graphs = []\n",
    "        for data in tqdm(data_set, desc=f\"Vectorizing {data_set_name} graphs\"):\n",
    "            # Create a unique file path based on the graph's dir attribute\n",
    "            file_path = os.path.join(\"vectorized_graphs\", f\"{data.dir}.pt\")\n",
    "\n",
    "            if os.path.exists(file_path):\n",
    "                data = torch.load(file_path)\n",
    "            else:\n",
    "                # If not, create the vectorized graph\n",
    "                vectorized_entities = vectorizer.transform(data.entities_list)\n",
    "                vectorized_entities = vectorized_entities.toarray()\n",
    "                vectorized_entities = torch.from_numpy(vectorized_entities).float()\n",
    "\n",
    "                # Ensure feature dimensions match, handling potential empty lists\n",
    "                if vectorized_entities.shape[0] == 0:\n",
    "                    # Handle graphs with no entities\n",
    "                    vectorized_entities = torch.zeros((0, num_features), dtype=torch.float32)\n",
    "\n",
    "                readout_node = torch.zeros((1, num_features), dtype=torch.float32)\n",
    "                data.x = torch.cat([vectorized_entities, readout_node], dim=0)\n",
    "\n",
    "                # Clean up attributes that are no longer needed\n",
    "                if hasattr(data, 'entities_list'):\n",
    "                    del data.entities_list\n",
    "                if hasattr(data, 'entities'):\n",
    "                    del data.entities\n",
    "                print(data.x.shape)\n",
    "                print(data.edge_index.shape)\n",
    "                print(data)\n",
    "                # Save the newly created graph to disk for future use\n",
    "                torch.save(data, file_path)\n",
    "\n",
    "            processed_graphs.append(data)\n",
    "            gc.collect()\n",
    "\n",
    "        # Replace the original dataset with the processed one\n",
    "        if data_set_name == \"train\":\n",
    "            train_data = processed_graphs\n",
    "        else:\n",
    "            test_data = processed_graphs\n",
    "\n",
    "    return train_data, test_data, vectorizer"
   ],
   "id": "1636334784967606",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T12:17:31.652169Z",
     "start_time": "2025-08-19T12:17:30.632157Z"
    }
   },
   "cell_type": "code",
   "source": "gc.collect()",
   "id": "cbb092accff9c570",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283489"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T12:18:01.682136Z",
     "start_time": "2025-08-19T12:17:31.695155Z"
    }
   },
   "cell_type": "code",
   "source": "train_graphs, test_graphs, vectorizer = get_vectorized_train_and_test_graphs()",
   "id": "222be4d304436701",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:05<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit tokenizer\n",
      "Processing train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing train graphs:   4%|▍         | 1/24 [00:00<00:03,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([241, 2254])\n",
      "torch.Size([2, 463])\n",
      "Data(x=[241, 2254], edge_index=[2, 463], y=[1], row_id=10056, dir='29', readout_mask=[241])\n",
      "torch.Size([370, 2254])\n",
      "torch.Size([2, 755])\n",
      "Data(x=[370, 2254], edge_index=[2, 755], y=[1], row_id=100406, dir='18', readout_mask=[370])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing train graphs:  12%|█▎        | 3/24 [00:00<00:04,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([214, 2254])\n",
      "torch.Size([2, 391])\n",
      "Data(x=[214, 2254], edge_index=[2, 391], y=[1], row_id=100495, dir='25', readout_mask=[214])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing train graphs:  17%|█▋        | 4/24 [00:00<00:04,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([220, 2254])\n",
      "torch.Size([2, 443])\n",
      "Data(x=[220, 2254], edge_index=[2, 443], y=[1], row_id=100150, dir='5', readout_mask=[220])\n",
      "torch.Size([282, 2254])\n",
      "torch.Size([2, 559])\n",
      "Data(x=[282, 2254], edge_index=[2, 559], y=[1], row_id=100581, dir='30', readout_mask=[282])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing train graphs:  25%|██▌       | 6/24 [00:01<00:03,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 2254])\n",
      "torch.Size([2, 487])\n",
      "Data(x=[240, 2254], edge_index=[2, 487], y=[1], row_id=100341, dir='14', readout_mask=[240])\n",
      "torch.Size([262, 2254])\n",
      "torch.Size([2, 505])\n",
      "Data(x=[262, 2254], edge_index=[2, 505], y=[1], row_id=100137, dir='4', readout_mask=[262])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing train graphs:  33%|███▎      | 8/24 [00:01<00:03,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([394, 2254])\n",
      "torch.Size([2, 837])\n",
      "Data(x=[394, 2254], edge_index=[2, 837], y=[1], row_id=100194, dir='10', readout_mask=[394])\n",
      "torch.Size([235, 2254])\n",
      "torch.Size([2, 499])\n",
      "Data(x=[235, 2254], edge_index=[2, 499], y=[1], row_id=100494, dir='24', readout_mask=[235])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing train graphs:  42%|████▏     | 10/24 [00:01<00:02,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([249, 2254])\n",
      "torch.Size([2, 530])\n",
      "Data(x=[249, 2254], edge_index=[2, 530], y=[1], row_id=100557, dir='28', readout_mask=[249])\n",
      "torch.Size([123, 2254])\n",
      "torch.Size([2, 269])\n",
      "Data(x=[123, 2254], edge_index=[2, 269], y=[1], row_id=100156, dir='6', readout_mask=[123])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing train graphs:  50%|█████     | 12/24 [00:02<00:02,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([283, 2254])\n",
      "torch.Size([2, 574])\n",
      "Data(x=[283, 2254], edge_index=[2, 574], y=[1], row_id=100312, dir='13', readout_mask=[283])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing train graphs:  54%|█████▍    | 13/24 [00:02<00:02,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([90, 2254])\n",
      "torch.Size([2, 175])\n",
      "Data(x=[90, 2254], edge_index=[2, 175], y=[1], row_id=10045, dir='21', readout_mask=[90])\n",
      "torch.Size([311, 2254])\n",
      "torch.Size([2, 614])\n",
      "Data(x=[311, 2254], edge_index=[2, 614], y=[1], row_id=100422, dir='20', readout_mask=[311])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing train graphs:  62%|██████▎   | 15/24 [00:02<00:01,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([122, 2254])\n",
      "torch.Size([2, 246])\n",
      "Data(x=[122, 2254], edge_index=[2, 246], y=[1], row_id=100374, dir='17', readout_mask=[122])\n",
      "torch.Size([222, 2254])\n",
      "torch.Size([2, 386])\n",
      "Data(x=[222, 2254], edge_index=[2, 386], y=[1], row_id=100069, dir='1', readout_mask=[222])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing train graphs:  71%|███████   | 17/24 [00:03<00:01,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([218, 2254])\n",
      "torch.Size([2, 466])\n",
      "Data(x=[218, 2254], edge_index=[2, 466], y=[1], row_id=10019, dir='9', readout_mask=[218])\n",
      "torch.Size([290, 2254])\n",
      "torch.Size([2, 536])\n",
      "Data(x=[290, 2254], edge_index=[2, 536], y=[1], row_id=100230, dir='12', readout_mask=[290])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing train graphs:  79%|███████▉  | 19/24 [00:03<00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([287, 2254])\n",
      "torch.Size([2, 567])\n",
      "Data(x=[287, 2254], edge_index=[2, 567], y=[1], row_id=100541, dir='27', readout_mask=[287])\n",
      "torch.Size([274, 2254])\n",
      "torch.Size([2, 563])\n",
      "Data(x=[274, 2254], edge_index=[2, 563], y=[1], row_id=100130, dir='3', readout_mask=[274])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing train graphs:  88%|████████▊ | 21/24 [00:03<00:00,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([237, 2254])\n",
      "torch.Size([2, 482])\n",
      "Data(x=[237, 2254], edge_index=[2, 482], y=[1], row_id=100418, dir='19', readout_mask=[237])\n",
      "torch.Size([547, 2254])\n",
      "torch.Size([2, 1147])\n",
      "Data(x=[547, 2254], edge_index=[2, 1147], y=[1], row_id=100360, dir='15', readout_mask=[547])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing train graphs:  96%|█████████▌| 23/24 [00:04<00:00,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([321, 2254])\n",
      "torch.Size([2, 663])\n",
      "Data(x=[321, 2254], edge_index=[2, 663], y=[1], row_id=100535, dir='26', readout_mask=[321])\n",
      "torch.Size([135, 2254])\n",
      "torch.Size([2, 292])\n",
      "Data(x=[135, 2254], edge_index=[2, 292], y=[1], row_id=100101, dir='2', readout_mask=[135])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing train graphs: 100%|██████████| 24/24 [00:04<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing test graphs:  17%|█▋        | 1/6 [00:00<00:00,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([296, 2254])\n",
      "torch.Size([2, 573])\n",
      "Data(x=[296, 2254], edge_index=[2, 573], y=[1], row_id=100490, dir='23', readout_mask=[296])\n",
      "torch.Size([170, 2254])\n",
      "torch.Size([2, 364])\n",
      "Data(x=[170, 2254], edge_index=[2, 364], y=[1], row_id=100182, dir='7', readout_mask=[170])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing test graphs:  50%|█████     | 3/6 [00:00<00:00,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([238, 2254])\n",
      "torch.Size([2, 353])\n",
      "Data(x=[238, 2254], edge_index=[2, 353], y=[1], row_id=100213, dir='11', readout_mask=[238])\n",
      "torch.Size([446, 2254])\n",
      "torch.Size([2, 882])\n",
      "Data(x=[446, 2254], edge_index=[2, 882], y=[1], row_id=100362, dir='16', readout_mask=[446])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing test graphs:  83%|████████▎ | 5/6 [00:00<00:00,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([261, 2254])\n",
      "torch.Size([2, 555])\n",
      "Data(x=[261, 2254], edge_index=[2, 555], y=[1], row_id=100185, dir='8', readout_mask=[261])\n",
      "torch.Size([176, 2254])\n",
      "torch.Size([2, 354])\n",
      "Data(x=[176, 2254], edge_index=[2, 354], y=[1], row_id=100477, dir='22', readout_mask=[176])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing test graphs: 100%|██████████| 6/6 [00:01<00:00,  5.77it/s]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T08:10:43.098477Z",
     "start_time": "2025-08-19T08:10:43.094621Z"
    }
   },
   "cell_type": "code",
   "source": "train_graphs[0]",
   "id": "631cf844d317666e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[241, 2254], edge_index=[2, 489], y=[1], entities_list=[240], row_id=10056, dir='29', readout_mask=[241])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T09:58:00.531643Z",
     "start_time": "2025-08-18T09:58:00.493983Z"
    }
   },
   "cell_type": "code",
   "source": "np.where(np.array([\"sepsis\" in  \" \".join(train_graphs[i].entities_list).lower() for i in range(len(train_graphs))]))",
   "id": "5b4ea7fb2d9cff58",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6049,  7658, 11966]),)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T09:58:15.877559Z",
     "start_time": "2025-08-18T09:58:15.872705Z"
    }
   },
   "cell_type": "code",
   "source": "train_graphs[6049].row_id",
   "id": "3751588b662633cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48495"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T09:58:16.197017Z",
     "start_time": "2025-08-18T09:58:16.190487Z"
    }
   },
   "cell_type": "code",
   "source": "train_graphs[6049].entities_list",
   "id": "28ad7ec3bf004bb0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GI Bleed',\n",
       " 'Whipple disease',\n",
       " 'Diabetes Mellitus (DM)',\n",
       " 'Hypertension (HTN)',\n",
       " 'Hyperlipidemia (HLD)',\n",
       " 'Urosepsis',\n",
       " 'Melena',\n",
       " 'Obstructive stone (5 mm in right UPJ)',\n",
       " 'Percutaneous Nephrostomy (PNT)',\n",
       " 'Esophagogastroduodenoscopy (EGD)',\n",
       " 'Capsule study',\n",
       " 'Gastroesophageal (GE) junction blockage',\n",
       " 'Hematocrit (HCT) drop',\n",
       " 'Red Blood Cell (RBC) transfusions',\n",
       " 'Colonoscopy',\n",
       " 'Outpatient follow-up',\n",
       " 'Productive cough',\n",
       " 'Left leg knee pain',\n",
       " 'Intramuscular injection (back of knee)',\n",
       " 'Bilateral buttock rash',\n",
       " 'Hemoglobin (Hb) 5.7',\n",
       " 'Hematocrit (HCT) 19.1',\n",
       " 'Melanotic stools',\n",
       " 'Hypotension',\n",
       " 'Intravenous (IV) Proton Pump Inhibitor (PPI)',\n",
       " 'Packed Red Blood Cells (PRBC)',\n",
       " 'NPO (nothing by mouth) for scope',\n",
       " 'Urinalysis (UA) with infection',\n",
       " 'Leukocytes in urine',\n",
       " 'Blood in urine',\n",
       " 'Red Blood Cells (RBC) in urine',\n",
       " 'White Blood Cells (WBC) in urine',\n",
       " 'Bacteria in urine',\n",
       " 'Ceftriaxone (CTX)',\n",
       " 'Insulin',\n",
       " 'Dextrose',\n",
       " 'Calcium gluconate',\n",
       " 'Creatinine (Cr) 3.3',\n",
       " 'Hyperkalemia (6.2)',\n",
       " 'Lactate 1.3',\n",
       " 'Nephrolithiasis',\n",
       " 'Pyelonephritis']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T09:58:25.594964Z",
     "start_time": "2025-08-18T09:58:25.579296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "note = json.load(open(f\"batched_notes/{train_graphs[6049].dir}.json\", \"r\"))\n",
    "print(note[\"text\"])"
   ],
   "id": "f26ed73003b01770",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Name:  ___                  Unit No:   ___\n",
      " \n",
      "Admission Date:  ___              Discharge Date:   ___\n",
      " \n",
      "Date of Birth:  ___             Sex:   M\n",
      " \n",
      "Service: MEDICINE\n",
      " \n",
      "Allergies: \n",
      "Penicillins / flu vaccine\n",
      " \n",
      "Attending: ___.\n",
      " \n",
      "Chief Complaint:\n",
      "GI Bleed\n",
      " \n",
      "History of Present Illness:\n",
      " Mr. ___ is an ___ year old man with history of Whipple in \n",
      "___, now insulin dependent, HTN, HLD who is admitted to the \n",
      "MICU for GI bleed. \n",
      "\n",
      "Patient was recently admitted from ___ to ___ for \n",
      "urospesis complicated by melena. He was found to have a 5 mm \n",
      "obstructive stone in his right UPJ s/p PNT. On ___ patient's \n",
      "hct dropped from 30 to 20 requiring 6 RBC transfusions. Plan was \n",
      "to follow up as an outpatient. GI was consulted at the time and \n",
      "performed EGD showing no source for the bleed. Capsule study was \n",
      "then attempted but incomplete because it became blocked at the \n",
      "GE junction. Given that his HCT remained stable, GI recommended \n",
      "colonoscopy and capsule study as an outpatient. Hct on discharge \n",
      "29.6, HCT at OSH today 21.8. Denies bloody stools since \n",
      "discharge.\n",
      "\n",
      "In the interim the patient had been feeling well in rehab making \n",
      "good progress until the day of admission. He felt more fatigued. \n",
      "Upon sitting on the toilet to have a BM he lost consciousness, \n",
      "but a nurse was present and caught him. He never fell or hit his \n",
      "head. He was subsequently transferred to his bed, slept for 1 \n",
      "hour and then woke up to work with ___. Upon standing up he felt \n",
      "light headed and lay back down.  Labs were done at facility. \n",
      "Showed HCT of 21. He has not had any melena since leaving the \n",
      "hospital.  \n",
      "\n",
      "Reports recent productive cough, but denies chest pain, SOB, \n",
      "fevers, chills, nausea, vomiting. Reports left leg knee pain and \n",
      "receiving injection in the back of the knee. \n",
      "\n",
      "In the ED, initial vitals:  97.5  96 109/57 97% RA. Exam in the \n",
      "ED notable for him appearing fatigue and pale,  Abdomen soft, \n",
      "non-tender, non-distended, no CVA tenderness, PNT without \n",
      "evidence of infection. Buttocks with rash bilaterally, no \n",
      "evidence of skin breakdown. Rectal exam with no frank blood. \n",
      "Guaiac positive. \n",
      "\n",
      "CBC notable for H/H of 5.7/19.1.  Patient had 2 large melanotic \n",
      "stools, after the first became hypotensive to the ___ and \n",
      "improved to 110s. He was transfused 2 units of PRBC. GI was \n",
      "consulted and recommended IV PPI, transfusion, and NPO for scope \n",
      "in AM. \n",
      "\n",
      "UA was also concerning for infection (Lg leuks, blood, 48 RBC 65 \n",
      "WBc and few bacteria). Patient was given 1 dose of CTX. Labs \n",
      "were notable for Cr 3.3 (baseline 1.6) hyperkalemia of 6.2 pt \n",
      "was given 10U of insulin and dextrose and give calcium \n",
      "gluconate. Lactate 1.3\n",
      "\n",
      "On transfer, vitals were:  98.3 94 136/53 24  94% RA \n",
      " \n",
      "On arrival to the MICU, patient reports feeling better. Still \n",
      "feels fatigued. Denies any abdominal pain, nausea, vomiting. No \n",
      "lightheadedness when he sits up. \n",
      "  \n",
      "Past Medical History:\n",
      "DM\n",
      "HTN\n",
      "dyslipidemia\n",
      "Nephrolithiasis\n",
      "Pyelonephritis\n",
      "GI bleed\n",
      " \n",
      "Social History:\n",
      "___\n",
      "Physical Exam:\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T09:58:52.168901Z",
     "start_time": "2025-08-18T09:58:31.749541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "session = get_session()\n",
    "valid_row_ids = get_valid_note_row_ids(session)"
   ],
   "id": "78b684e9b0195fd0",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m session = get_session()\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m valid_row_ids = \u001B[43mget_valid_note_row_ids\u001B[49m\u001B[43m(\u001B[49m\u001B[43msession\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 3\u001B[39m, in \u001B[36mget_valid_note_row_ids\u001B[39m\u001B[34m(session)\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_valid_note_row_ids\u001B[39m(session):\n\u001B[32m      2\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Necessary because in my prevoius filtering steps I didnt excluded them and KG creation is still running (dont want interrupt)\"\"\"\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     db_note_row_ids = \u001B[43msession\u001B[49m\u001B[43m.\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m(\u001B[49m\u001B[43mPreprocessedRevisedNote\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrow_id\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfilter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mand_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43mPreprocessedRevisedNote\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnot_like\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[33;43mepsis\u001B[39;49m\u001B[33;43m%\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43mPreprocessedRevisedNote\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnot_like\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[33;43meptic\u001B[39;49m\u001B[33;43m%\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43mPreprocessedRevisedNote\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnot_like\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[33;43mhock\u001B[39;49m\u001B[33;43m%\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mall\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m     db_note_row_ids = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m n: n[\u001B[32m0\u001B[39m], db_note_row_ids))\n\u001B[32m      5\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m db_note_row_ids\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\git\\KARDIA\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\query.py:2704\u001B[39m, in \u001B[36mQuery.all\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   2682\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mall\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> List[_T]:\n\u001B[32m   2683\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Return the results represented by this :class:`_query.Query`\u001B[39;00m\n\u001B[32m   2684\u001B[39m \u001B[33;03m    as a list.\u001B[39;00m\n\u001B[32m   2685\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   2702\u001B[39m \u001B[33;03m        :meth:`_engine.Result.scalars` - v2 comparable method.\u001B[39;00m\n\u001B[32m   2703\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2704\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_iter\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m.all()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\git\\KARDIA\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\query.py:2857\u001B[39m, in \u001B[36mQuery._iter\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   2854\u001B[39m params = \u001B[38;5;28mself\u001B[39m._params\n\u001B[32m   2856\u001B[39m statement = \u001B[38;5;28mself\u001B[39m._statement_20()\n\u001B[32m-> \u001B[39m\u001B[32m2857\u001B[39m result: Union[ScalarResult[_T], Result[_T]] = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msession\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2858\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2859\u001B[39m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2860\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexecution_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m_sa_orm_load_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mload_options\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2861\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2863\u001B[39m \u001B[38;5;66;03m# legacy: automatically set scalars, unique\u001B[39;00m\n\u001B[32m   2864\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m result._attributes.get(\u001B[33m\"\u001B[39m\u001B[33mis_single_entity\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\git\\KARDIA\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:2365\u001B[39m, in \u001B[36mSession.execute\u001B[39m\u001B[34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event)\u001B[39m\n\u001B[32m   2305\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mexecute\u001B[39m(\n\u001B[32m   2306\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   2307\u001B[39m     statement: Executable,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2313\u001B[39m     _add_event: Optional[Any] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   2314\u001B[39m ) -> Result[Any]:\n\u001B[32m   2315\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Execute a SQL expression construct.\u001B[39;00m\n\u001B[32m   2316\u001B[39m \n\u001B[32m   2317\u001B[39m \u001B[33;03m    Returns a :class:`_engine.Result` object representing\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   2363\u001B[39m \n\u001B[32m   2364\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2365\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_execute_internal\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2366\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2367\u001B[39m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2368\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexecution_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexecution_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2369\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbind_arguments\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbind_arguments\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2370\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_parent_execute_state\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_parent_execute_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2371\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_add_event\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_add_event\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2372\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\git\\KARDIA\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:2251\u001B[39m, in \u001B[36mSession._execute_internal\u001B[39m\u001B[34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event, _scalar_result)\u001B[39m\n\u001B[32m   2246\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m conn.scalar(\n\u001B[32m   2247\u001B[39m         statement, params \u001B[38;5;129;01mor\u001B[39;00m {}, execution_options=execution_options\n\u001B[32m   2248\u001B[39m     )\n\u001B[32m   2250\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m compile_state_cls:\n\u001B[32m-> \u001B[39m\u001B[32m2251\u001B[39m     result: Result[Any] = \u001B[43mcompile_state_cls\u001B[49m\u001B[43m.\u001B[49m\u001B[43morm_execute_statement\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2252\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   2253\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2254\u001B[39m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2255\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexecution_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2256\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbind_arguments\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2257\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2258\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2259\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2260\u001B[39m     result = conn.execute(\n\u001B[32m   2261\u001B[39m         statement, params \u001B[38;5;129;01mor\u001B[39;00m {}, execution_options=execution_options\n\u001B[32m   2262\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\git\\KARDIA\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\context.py:306\u001B[39m, in \u001B[36mAbstractORMCompileState.orm_execute_statement\u001B[39m\u001B[34m(cls, session, statement, params, execution_options, bind_arguments, conn)\u001B[39m\n\u001B[32m    296\u001B[39m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[32m    297\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34morm_execute_statement\u001B[39m(\n\u001B[32m    298\u001B[39m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    304\u001B[39m     conn,\n\u001B[32m    305\u001B[39m ) -> Result:\n\u001B[32m--> \u001B[39m\u001B[32m306\u001B[39m     result = \u001B[43mconn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    307\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecution_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexecution_options\u001B[49m\n\u001B[32m    308\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    309\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m.orm_setup_cursor_result(\n\u001B[32m    310\u001B[39m         session,\n\u001B[32m    311\u001B[39m         statement,\n\u001B[32m   (...)\u001B[39m\u001B[32m    315\u001B[39m         result,\n\u001B[32m    316\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\git\\KARDIA\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1415\u001B[39m, in \u001B[36mConnection.execute\u001B[39m\u001B[34m(self, statement, parameters, execution_options)\u001B[39m\n\u001B[32m   1413\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc.ObjectNotExecutableError(statement) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   1414\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1415\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmeth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1416\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1417\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdistilled_parameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1418\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexecution_options\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mNO_OPTIONS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1419\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\git\\KARDIA\\.venv\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:523\u001B[39m, in \u001B[36mClauseElement._execute_on_connection\u001B[39m\u001B[34m(self, connection, distilled_params, execution_options)\u001B[39m\n\u001B[32m    521\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n\u001B[32m    522\u001B[39m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, Executable)\n\u001B[32m--> \u001B[39m\u001B[32m523\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconnection\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execute_clauseelement\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    524\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdistilled_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecution_options\u001B[49m\n\u001B[32m    525\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    526\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    527\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc.ObjectNotExecutableError(\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\git\\KARDIA\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1637\u001B[39m, in \u001B[36mConnection._execute_clauseelement\u001B[39m\u001B[34m(self, elem, distilled_parameters, execution_options)\u001B[39m\n\u001B[32m   1625\u001B[39m compiled_cache: Optional[CompiledCacheType] = execution_options.get(\n\u001B[32m   1626\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcompiled_cache\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m.engine._compiled_cache\n\u001B[32m   1627\u001B[39m )\n\u001B[32m   1629\u001B[39m compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\n\u001B[32m   1630\u001B[39m     dialect=dialect,\n\u001B[32m   1631\u001B[39m     compiled_cache=compiled_cache,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1635\u001B[39m     linting=\u001B[38;5;28mself\u001B[39m.dialect.compiler_linting | compiler.WARN_LINTING,\n\u001B[32m   1636\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m1637\u001B[39m ret = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_execute_context\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1638\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1639\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecution_ctx_cls\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_init_compiled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1640\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompiled_sql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1641\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdistilled_parameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1642\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexecution_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1643\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompiled_sql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1644\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdistilled_parameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1645\u001B[39m \u001B[43m    \u001B[49m\u001B[43melem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1646\u001B[39m \u001B[43m    \u001B[49m\u001B[43mextracted_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1647\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_hit\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_hit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1648\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1649\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_events:\n\u001B[32m   1650\u001B[39m     \u001B[38;5;28mself\u001B[39m.dispatch.after_execute(\n\u001B[32m   1651\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1652\u001B[39m         elem,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1656\u001B[39m         ret,\n\u001B[32m   1657\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\git\\KARDIA\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1842\u001B[39m, in \u001B[36mConnection._execute_context\u001B[39m\u001B[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001B[39m\n\u001B[32m   1840\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exec_insertmany_context(dialect, context)\n\u001B[32m   1841\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1842\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_exec_single_context\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1843\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\n\u001B[32m   1844\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\git\\KARDIA\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1982\u001B[39m, in \u001B[36mConnection._exec_single_context\u001B[39m\u001B[34m(self, dialect, context, statement, parameters)\u001B[39m\n\u001B[32m   1979\u001B[39m     result = context._setup_result_proxy()\n\u001B[32m   1981\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m-> \u001B[39m\u001B[32m1982\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_handle_dbapi_exception\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1983\u001B[39m \u001B[43m        \u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstr_statement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meffective_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\n\u001B[32m   1984\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1986\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\git\\KARDIA\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2354\u001B[39m, in \u001B[36mConnection._handle_dbapi_exception\u001B[39m\u001B[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001B[39m\n\u001B[32m   2352\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2353\u001B[39m         \u001B[38;5;28;01massert\u001B[39;00m exc_info[\u001B[32m1\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2354\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m exc_info[\u001B[32m1\u001B[39m].with_traceback(exc_info[\u001B[32m2\u001B[39m])\n\u001B[32m   2355\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m   2356\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m._reentrant_error\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\git\\KARDIA\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1963\u001B[39m, in \u001B[36mConnection._exec_single_context\u001B[39m\u001B[34m(self, dialect, context, statement, parameters)\u001B[39m\n\u001B[32m   1961\u001B[39m                 \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1962\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m evt_handled:\n\u001B[32m-> \u001B[39m\u001B[32m1963\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdo_execute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1964\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstr_statement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meffective_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\n\u001B[32m   1965\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1967\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._has_events \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.engine._has_events:\n\u001B[32m   1968\u001B[39m     \u001B[38;5;28mself\u001B[39m.dispatch.after_cursor_execute(\n\u001B[32m   1969\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1970\u001B[39m         cursor,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1974\u001B[39m         context.executemany,\n\u001B[32m   1975\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\git\\KARDIA\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:943\u001B[39m, in \u001B[36mDefaultDialect.do_execute\u001B[39m\u001B[34m(self, cursor, statement, parameters, context)\u001B[39m\n\u001B[32m    942\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdo_execute\u001B[39m(\u001B[38;5;28mself\u001B[39m, cursor, statement, parameters, context=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m--> \u001B[39m\u001B[32m943\u001B[39m     \u001B[43mcursor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\utf_8.py:15\u001B[39m, in \u001B[36mdecode\u001B[39m\u001B[34m(input, errors)\u001B[39m\n\u001B[32m     11\u001B[39m \u001B[38;5;66;03m### Codec APIs\u001B[39;00m\n\u001B[32m     13\u001B[39m encode = codecs.utf_8_encode\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecode\u001B[39m(\u001B[38;5;28minput\u001B[39m, errors=\u001B[33m'\u001B[39m\u001B[33mstrict\u001B[39m\u001B[33m'\u001B[39m):\n\u001B[32m     16\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m codecs.utf_8_decode(\u001B[38;5;28minput\u001B[39m, errors, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mIncrementalEncoder\u001B[39;00m(codecs.IncrementalEncoder):\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e7db78a3c9012b50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:39:30.148172Z",
     "start_time": "2025-08-18T11:39:30.136215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn.conv import SAGEConv, GCNConv\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, dropout, heads=1, heads_dropout = .0):\n",
    "       super(GNN, self).__init__()\n",
    "       self.conv1 = SAGEConv(in_dim, hidden_dim, project=False, aggr=\"sum\") #SAGEConv(in_dim, hidden_dim, project=False, aggr=\"sum\")#GATConv(in_dim, hidden_dim,  add_self_loops=False, heads=heads, concat=True) #edge_dim=hidden_dim,\n",
    "       self.conv2 = GATConv(hidden_dim*1, 1, add_self_loops=False, concat=False, heads=heads, dropout=heads_dropout) # edge_dim=hidden_dim,\n",
    "       self.dropout = torch.nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index, **kwargs):\n",
    "        # x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv1(x, edge_index)#, edge_attr\n",
    "        # x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x, (edge_index_attn, alpha) = self.conv2(x, edge_index, return_attention_weights=True) #, edge_attr\n",
    "        return x, (edge_index_attn, alpha)\n",
    "\n"
   ],
   "id": "a4724780611b88de",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:39:30.297584Z",
     "start_time": "2025-08-18T11:39:30.295516Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d6bbf71798a76c0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:39:30.572248Z",
     "start_time": "2025-08-18T11:39:30.564101Z"
    }
   },
   "cell_type": "code",
   "source": [
    " def evaluate(model, loader, device):\n",
    "    \"\"\"Evaluates the model and returns AUROC and AUPRC.\"\"\"\n",
    "    model = model.to(device)\n",
    "    with torch.inference_mode():\n",
    "       model.eval()\n",
    "       pred_probas = []\n",
    "       y_trues = []\n",
    "       for batch_data in loader:\n",
    "          batch_data = batch_data.to(device)\n",
    "          logit, _ = model(batch_data.x, batch_data.edge_index, edge_attr=batch_data.edge_attr)\n",
    "          logit = logit[batch_data.readout_mask]\n",
    "          pred_proba = torch.sigmoid(logit)\n",
    "          pred_probas.extend(pred_proba.cpu().tolist())\n",
    "          y_trues.extend(batch_data.y.cpu().tolist())\n",
    "\n",
    "    y_true = np.array(y_trues)\n",
    "    y_pred_proba = np.array(pred_probas)\n",
    "    auroc = metrics.roc_auc_score(y_true, y_pred_proba)\n",
    "    auprc = metrics.average_precision_score(y_true, y_pred_proba)\n",
    "    return auroc, auprc"
   ],
   "id": "291a3e7424771d21",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:39:30.942304Z",
     "start_time": "2025-08-18T11:39:30.891557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N_SPLITS = 3\n",
    "MAX_EVALS = 50\n",
    "SEED = 50 #0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "final_generator = set_all_seeds(SEED)"
   ],
   "id": "f6dc8b0bf1feffe6",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:39:31.217370Z",
     "start_time": "2025-08-18T11:39:31.209031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "space = {\n",
    "    # \"hidden_dim\": hp.choice('hidden_dim', [8, 16, 32]),\n",
    "    \"dropout\": hp.loguniform('dropout', np.log(1e-2), np.log(1e-1)),\n",
    "    \"heads_dropout\": hp.loguniform('heads_dropout', np.log(1e-2), np.log(2e-1)),\n",
    "    \"lr\": hp.loguniform('lr', np.log(1e-3), np.log(1e-2)),\n",
    "    # \"weight_decay\": hp.loguniform('weight_decay', np.log(1e-6), np.log(1e-3)),\n",
    "    \"weight_decay\": hp.choice('weight_decay', [0]),\n",
    "    \"heads\": hp.quniform('heads', 1, 6, 1),\n",
    "    # \"batch_size\": hp.quniform('batch_size', 16, 128, 16),\n",
    "    \"epochs\": hp.quniform('epochs', 10, 200, 1) # Epochs are now tunable\n",
    "}"
   ],
   "id": "2a6aa899b4f2f85e",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:48:57.207423Z",
     "start_time": "2025-08-18T11:48:57.182516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_train_full = [d.y.item() for d in train_graphs]\n",
    "# best_hyperparams = {'batch_size': 256, 'dropout': 0.8, 'epochs': 600, 'heads': 2, 'hidden_dim': 16, 'lr': .01, 'weight_decay': 1e-5, \"heads_dropout\": .1}\n",
    "# best_hyperparams = {'batch_size': 256, 'dropout': 0.0, 'epochs': 40, 'heads': 2, 'hidden_dim': 1, 'lr': .01, 'weight_decay': 1e-5, \"heads_dropout\": .1}\n",
    "best_hyperparams = {'batch_size': 256, 'dropout': 0.3, 'epochs': 100, 'heads': 1, 'hidden_dim': 4, 'lr': .01, 'weight_decay': 0, \"heads_dropout\": 0.2}"
   ],
   "id": "f7bc3c9b1173c102",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:48:57.586370Z",
     "start_time": "2025-08-18T11:48:57.582156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(loss_fn, loader, best_hyperparams):\n",
    "    model = GNN(\n",
    "                in_dim=train_graphs[0].x.shape[1],\n",
    "                hidden_dim=best_hyperparams[\"hidden_dim\"],\n",
    "                dropout=best_hyperparams[\"dropout\"],\n",
    "                heads=best_hyperparams[\"heads\"],\n",
    "                heads_dropout=best_hyperparams[\"heads_dropout\"]\n",
    "    ).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_hyperparams[\"lr\"], weight_decay=best_hyperparams[\"weight_decay\"])\n",
    "    for epoch in range(best_hyperparams['epochs']):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for batch_data in loader:\n",
    "           optimizer.zero_grad()\n",
    "           batch_data = batch_data.to(device)\n",
    "           logit, _ = model(batch_data.x, batch_data.edge_index)\n",
    "           logit = logit[batch_data.readout_mask]\n",
    "           loss = loss_fn(logit.squeeze(), batch_data.y)\n",
    "           loss.backward()\n",
    "           optimizer.step()\n",
    "           epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(final_train_loader)\n",
    "        #print(f\"Epoch: {epoch} Train AUROC: {auroc_train:.4f} | Test AUROC: {auroc_test:.4f}\")\n",
    "    return model"
   ],
   "id": "d2586820fdc03b67",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:48:58.126489Z",
     "start_time": "2025-08-18T11:48:58.119436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def tune_hyperparameters(train_graphs, y_train_full, space_params, k = 3, max_evals = 50, maximize_metric = True):\n",
    "\n",
    "    def objective(params):\n",
    "        if 'epochs' in params:\n",
    "            params['epochs'] = int(params['epochs'])\n",
    "        if 'heads' in params:\n",
    "            params['heads'] = int(params['heads'])\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "        scores = []\n",
    "\n",
    "        for train_index, val_index in skf.split(train_graphs, y_train_full):\n",
    "            inner_train_graphs = itemgetter(*train_index)(train_graphs)\n",
    "            inner_val_graphs = itemgetter(*val_index)(train_graphs)\n",
    "            inner_train_graphs = [graph.to(device) for graph in inner_train_graphs]\n",
    "            inner_val_graphs = [graph.to(device) for graph in inner_val_graphs]\n",
    "            inner_train_loader = DataLoader(\n",
    "                inner_train_graphs,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                worker_init_fn=seed_worker,\n",
    "                generator=final_generator\n",
    "            )\n",
    "            inner_val_loader = DataLoader(\n",
    "                inner_val_graphs,\n",
    "                batch_size=256,\n",
    "                shuffle=False\n",
    "            )\n",
    "            pos_weight = ceil(sum([data.y[0] == 0 for data in inner_train_graphs]) / sum([data.y[0] == 1 for data in inner_train_graphs]))\n",
    "            loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=device))\n",
    "            model = train(loss_fn, inner_train_loader, best_hyperparams)\n",
    "            auroc_test, auprc_test = evaluate(model, inner_val_loader, device)\n",
    "            #auroc_train, auprc_train = evaluate(model, final_train_loader, device)\n",
    "            scores.append(auroc_test)\n",
    "\n",
    "        average_score = np.mean(scores)\n",
    "        \n",
    "        loss = -average_score if maximize_metric else average_score\n",
    "\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "    trials = Trials()\n",
    "    best_params = fmin(\n",
    "        fn=objective,\n",
    "        space=space_params,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_evals,\n",
    "        trials=trials,\n",
    "        rstate=np.random.default_rng(42)\n",
    "    )\n",
    "\n",
    "    best_metric_score = -trials.best_trial['result']['loss'] if maximize_metric else trials.best_trial['result']['loss']\n",
    "\n",
    "    return best_params, best_metric_score"
   ],
   "id": "3430452a720e6bea",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:48:58.353149Z",
     "start_time": "2025-08-18T11:48:58.351216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# best_hyperparams, best_metric_score = tune_hyperparameters(train_graphs, y_train_full, space, max_evals=100, maximize_metric = True, k = 5)\n",
    "# best_hyperparams, best_metric_score"
   ],
   "id": "99a81aca099f2498",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:48:58.755361Z",
     "start_time": "2025-08-18T11:48:58.753030Z"
    }
   },
   "cell_type": "code",
   "source": "## TODO add self loop for all besides the last node",
   "id": "4aabc693a9cea5d5",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:48:59.212937Z",
     "start_time": "2025-08-18T11:48:59.194557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DataLoaders for final training\n",
    "# train_graphs = [graph.to(device) for graph in train_graphs]\n",
    "# test_graphs = [graph.to(device) for graph in test_graphs]\n",
    "final_train_loader = DataLoader(\n",
    "    train_graphs,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=final_generator\n",
    ")\n",
    "# Test loader does not need to be shuffled\n",
    "test_loader = DataLoader(\n",
    "    test_graphs,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# Instantiate the final model\n",
    "final_model = GNN(\n",
    "    in_dim=train_graphs[0].x.shape[1],\n",
    "    hidden_dim=1,\n",
    "    dropout=best_hyperparams[\"dropout\"],\n",
    "    heads=int(best_hyperparams[\"heads\"]),\n",
    "    heads_dropout=best_hyperparams[\"heads_dropout\"]\n",
    ").to(device)"
   ],
   "id": "230a1aa54f64294f",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:48:59.892741Z",
     "start_time": "2025-08-18T11:48:59.651925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = optim.Adam(\n",
    "    final_model.parameters(),\n",
    "    lr=best_hyperparams[\"lr\"],\n",
    "    weight_decay=best_hyperparams[\"weight_decay\"]\n",
    ")\n",
    "\n",
    "# Recalculate pos_weight on the full training data\n",
    "pos_weight = ceil(sum([data.y[0] == 0 for data in train_graphs]) / sum([data.y[0] == 1 for data in train_graphs]))\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=device))"
   ],
   "id": "dd5a9fbe810a4213",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:49:00.344776Z",
     "start_time": "2025-08-18T11:49:00.343029Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "57ef034617d856c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:57:27.385984Z",
     "start_time": "2025-08-18T11:49:00.672854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs_final = 10 #int(best_hyperparams['epochs'])\n",
    "for epoch in range(num_epochs_final):\n",
    "    epoch_loss = 0\n",
    "    final_model.train()\n",
    "    for batch_data in final_train_loader:\n",
    "       optimizer.zero_grad()\n",
    "       batch_data = batch_data.to(device)\n",
    "       logit, _ = final_model(batch_data.x, batch_data.edge_index)\n",
    "       logit = logit[batch_data.readout_mask]\n",
    "       loss = loss_fn(logit.squeeze(), batch_data.y)\n",
    "       loss.backward()\n",
    "       optimizer.step()\n",
    "       epoch_loss += loss.item()\n",
    "    avg_loss = epoch_loss / len(final_train_loader)\n",
    "    auroc_test, auprc_test = evaluate(final_model, test_loader, device)\n",
    "    auroc_train, auprc_train = evaluate(final_model, final_train_loader, device)\n",
    "\n",
    "    print(f\"Epoch: {epoch} Train AUROC: {auroc_train:.4f} | Test AUROC: {auroc_test:.4f}\")"
   ],
   "id": "334e42e8fcf182df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train AUROC: 0.7884 | Test AUROC: 0.7268\n",
      "Epoch: 1 Train AUROC: 0.8686 | Test AUROC: 0.8130\n",
      "Epoch: 2 Train AUROC: 0.8954 | Test AUROC: 0.8356\n",
      "Epoch: 3 Train AUROC: 0.9204 | Test AUROC: 0.8304\n",
      "Epoch: 4 Train AUROC: 0.9398 | Test AUROC: 0.8125\n",
      "Epoch: 5 Train AUROC: 0.9531 | Test AUROC: 0.8023\n",
      "Epoch: 6 Train AUROC: 0.9633 | Test AUROC: 0.7990\n",
      "Epoch: 7 Train AUROC: 0.9717 | Test AUROC: 0.8012\n",
      "Epoch: 8 Train AUROC: 0.9755 | Test AUROC: 0.8031\n",
      "Epoch: 9 Train AUROC: 0.9791 | Test AUROC: 0.7984\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T11:57:27.629007Z",
     "start_time": "2025-08-18T11:57:27.556178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_labels = np.array(list(map(lambda x: x.y[0].item(), train_graphs)))\n",
    "np.where(train_labels == 1)"
   ],
   "id": "78c91e38bd25779c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   39,    72,   112,   152,   227,   229,   233,   256,   266,\n",
       "          292,   347,   397,   406,   441,   470,   473,   494,   512,\n",
       "          517,   573,   593,   606,   646,   657,   658,   670,   757,\n",
       "          759,   782,   810,   849,   853,   858,   920,   943,   953,\n",
       "          980,  1032,  1044,  1051,  1081,  1091,  1116,  1151,  1166,\n",
       "         1167,  1212,  1229,  1245,  1249,  1270,  1275,  1292,  1429,\n",
       "         1486,  1520,  1558,  1581,  1647,  1673,  1677,  1719,  1723,\n",
       "         1753,  1769,  1784,  1815,  1932,  1952,  1999,  2029,  2059,\n",
       "         2063,  2067,  2074,  2089,  2111,  2117,  2118,  2120,  2136,\n",
       "         2141,  2150,  2201,  2251,  2272,  2288,  2292,  2317,  2335,\n",
       "         2336,  2345,  2369,  2423,  2468,  2481,  2551,  2602,  2641,\n",
       "         2669,  2730,  2741,  2774,  2800,  2804,  2857,  2874,  2905,\n",
       "         2962,  2977,  2988,  3032,  3066,  3067,  3086,  3093,  3100,\n",
       "         3117,  3176,  3183,  3186,  3227,  3233,  3248,  3299,  3300,\n",
       "         3315,  3380,  3393,  3444,  3449,  3461,  3504,  3530,  3534,\n",
       "         3572,  3595,  3633,  3642,  3667,  3705,  3709,  3714,  3777,\n",
       "         3818,  3832,  3833,  3856,  3981,  3984,  3989,  3990,  4067,\n",
       "         4078,  4082,  4090,  4133,  4194,  4285,  4303,  4323,  4340,\n",
       "         4374,  4392,  4403,  4422,  4450,  4456,  4501,  4522,  4532,\n",
       "         4535,  4537,  4583,  4585,  4598,  4650,  4659,  4731,  4782,\n",
       "         4835,  4905,  4985,  4989,  5002,  5028,  5045,  5055,  5063,\n",
       "         5070,  5113,  5134,  5146,  5157,  5226,  5242,  5245,  5323,\n",
       "         5340,  5370,  5376,  5382,  5397,  5443,  5501,  5527,  5586,\n",
       "         5601,  5632,  5670,  5689,  5691,  5702,  5704,  5731,  5855,\n",
       "         5857,  5904,  5948,  5961,  5983,  5989,  5994,  6009,  6043,\n",
       "         6076,  6099,  6103,  6122,  6168,  6174,  6226,  6264,  6309,\n",
       "         6313,  6351,  6357,  6384,  6398,  6427,  6432,  6479,  6481,\n",
       "         6485,  6487,  6512,  6514,  6617,  6713,  6727,  6733,  6735,\n",
       "         6737,  6781,  6829,  6891,  6898,  6906,  6917,  6931,  6941,\n",
       "         6971,  6989,  6999,  7035,  7058,  7078,  7154,  7159,  7175,\n",
       "         7184,  7211,  7217,  7221,  7257,  7261,  7275,  7292,  7312,\n",
       "         7331,  7420,  7526,  7538,  7540,  7543,  7560,  7572,  7634,\n",
       "         7724,  7741,  7743,  7826,  7860,  7891,  7893,  7900,  7942,\n",
       "         7976,  8000,  8011,  8105,  8247,  8291,  8379,  8389,  8407,\n",
       "         8415,  8437,  8462,  8527,  8530,  8535,  8545,  8606,  8607,\n",
       "         8612,  8621,  8638,  8654,  8684,  8703,  8781,  8806,  8827,\n",
       "         8829,  8843,  8845,  8933,  8941,  8957,  8969,  8976,  8985,\n",
       "         8994,  9011,  9016,  9019,  9023,  9051,  9081,  9092,  9172,\n",
       "         9187,  9211,  9212,  9225,  9230,  9262,  9283,  9307,  9319,\n",
       "         9341,  9364,  9418,  9475,  9484,  9537,  9558,  9559,  9580,\n",
       "         9614,  9617,  9621,  9643,  9650,  9718,  9724,  9749,  9774,\n",
       "         9789,  9816,  9825,  9888,  9949,  9953,  9957, 10007, 10012,\n",
       "        10027, 10074, 10099, 10100, 10178, 10189, 10230, 10269, 10275,\n",
       "        10328, 10404, 10457, 10465, 10488, 10493, 10511, 10524, 10539,\n",
       "        10557, 10630, 10632, 10641, 10663, 10679, 10692, 10697, 10701,\n",
       "        10752, 10776, 10780, 10825, 10857, 10859, 10883, 10892, 10928,\n",
       "        10940, 10956, 10970, 10977, 10995, 11033, 11064, 11086, 11099,\n",
       "        11122, 11189, 11268, 11314, 11357, 11358, 11372, 11404, 11431,\n",
       "        11550, 11568, 11582, 11595, 11598, 11601, 11634, 11681, 11704,\n",
       "        11746, 11779, 11831, 11833, 11854, 11956, 11962, 11986, 11992,\n",
       "        12015, 12026, 12045, 12054, 12055, 12065, 12180, 12224, 12225,\n",
       "        12248, 12299, 12329, 12362, 12369, 12382, 12409, 12418, 12436,\n",
       "        12453, 12497, 12521]),)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_labels = np.array(list(map(lambda x: x.y[0].item(), test_graphs)))\n",
    "np.where(test_labels == 1)"
   ],
   "id": "aecf8307f490b5f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_logits_and_attn_heads(batch_data):\n",
    "    with torch.inference_mode():\n",
    "        final_model.eval()\n",
    "        logits, (edge_idx, attn_out) = final_model(batch_data.x,batch_data.edge_index)\n",
    "        pred_proba = torch.sigmoid(logits[-1])\n",
    "    return logits[-1], attn_out\n",
    "\n",
    "def get_influence_scores(batch_data):\n",
    "    logits_control, attn_out = get_logits_and_attn_heads(batch_data)\n",
    "    mask = batch_data.edge_index[1] == (batch_data.x.shape[0]-1)\n",
    "    assert attn_out[mask].shape[0] == len(batch_data.entities_list), \"Doesnt match entities\"\n",
    "    assert (torch.sort(batch_data.edge_index[0][mask])[0] != batch_data.edge_index[0][mask]).sum() == 0, \"Is not sorted\"\n",
    "    #print(torch.sigmoid(logits_control), batch_data.y)\n",
    "    \n",
    "    w_l = final_model.state_dict()[\"conv1.lin_l.weight\"]\n",
    "    w_r = final_model.state_dict()[\"conv1.lin_r.weight\"]\n",
    "    rlt = final_model.state_dict()[\"conv2.lin.weight\"]\n",
    "    bl = final_model.state_dict()['conv1.lin_l.bias']\n",
    "    b2 = final_model.state_dict()['conv2.bias']\n",
    "        \n",
    "    left_aggr = torch.zeros_like(batch_data.x[:-1])\n",
    "    lifted_nodes = torch.index_select(batch_data.x[:-1], 0, batch_data.edge_index[0, ~mask])\n",
    "    left_aggr.scatter_reduce_(0,batch_data.edge_index[1, ~mask].repeat(batch_data.x.shape[-1], 1).t(), lifted_nodes, reduce=\"sum\")\n",
    "    \n",
    "    transformed_left = left_aggr @ w_l.t()\n",
    "    transformed_right = batch_data.x[:-1] @ w_r.t()\n",
    "    sage_out = transformed_left + transformed_right + bl\n",
    "    sage_out_transformed = sage_out @ rlt.t()\n",
    "    sage_out_weighted_transformed = sage_out_transformed * attn_out[mask]\n",
    "    logits = (sage_out_weighted_transformed.mean(-1)).sum() + b2\n",
    "    assert torch.allclose(logits, logits_control, rtol=1e-4, atol=1e-9), f\"Influence scores are wrong {logits.item()} - {logits_control.item()}\"\n",
    "    return sage_out_weighted_transformed.mean(-1).cpu()"
   ],
   "id": "dc65f64427ab5356",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_influence_scores(test_graphs[100])",
   "id": "b069c7bbc09ff1a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_influence_scores(batch_data):\n",
    "    ## Overall influence\n",
    "    font = {'family' : 'arial',\n",
    "            'weight' : 'bold',\n",
    "            'size'   : 14}\n",
    "    influence_scores = get_influence_scores(batch_data)\n",
    "    matplotlib.rc('font', **font)\n",
    "    plt.figure(figsize=(25, 4))\n",
    "    sorted_idx = influence_scores.abs().argsort(descending=True)\n",
    "    plt.bar(itemgetter(*sorted_idx)(batch_data.entities_list), influence_scores[sorted_idx])\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.title(\"Overall influence\")\n",
    "    plt.xlabel(\"Entities\")\n",
    "    plt.ylabel(\"Influence weight on prediction\")\n",
    "    plt.grid(which=\"both\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_influence_scores(train_graphs[-1])"
   ],
   "id": "cf024edefe7f9c19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_global_influence_scores():\n",
    "    summed_aggregated_influence_scores = torch.zeros(train_graphs[0].x.shape[-1])\n",
    "    graphs = train_graphs\n",
    "    for batch_data in graphs:\n",
    "        influence_scores = get_influence_scores(batch_data)\n",
    "        aggregated_influence_scores = torch.zeros_like(batch_data.x).cpu()\n",
    "        non_zero_idx = torch.nonzero(batch_data.x).cpu()\n",
    "        ## TODO Think about some kind of normalization here ? \n",
    "        aggregated_influence_scores[non_zero_idx[:, 0], non_zero_idx[:, 1]] = influence_scores[non_zero_idx[:, 0]]\n",
    "        summed_aggregated_influence_scores += aggregated_influence_scores.sum(0)\n",
    "    return summed_aggregated_influence_scores / len(graphs)\n",
    "\n",
    "global_influence_scores = get_global_influence_scores()"
   ],
   "id": "382220d521e72ba9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8780ed1ecc21560e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_k = 20\n",
    "global_influence_scores_sort_idx = global_influence_scores.argsort(descending=True)[:top_k]\n",
    "plt.figure(figsize=(25, 4))\n",
    "plt.bar(vectorizer.get_feature_names_out()[global_influence_scores_sort_idx], global_influence_scores[global_influence_scores_sort_idx])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title(\"Global influence of tokens\")\n",
    "plt.xlabel(\"Tokens\")\n",
    "plt.ylabel(\"Global influence weight\")\n",
    "plt.grid(which=\"both\")\n",
    "plt.show()"
   ],
   "id": "14aa0e7234e54cd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "## Check how important edges are overall - is solely readout enough and dont we even need the links between entities or are they important? -> If not KG procedure is not necessary",
   "id": "31ffafa05a107125",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sage_out_weighted_transformed.mean(-1).cpu().sum()",
   "id": "4991748ba3874ac4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "itemgetter(*attn_out.mean(-1)[mask].argsort(descending=True))(batch_data.entities_list), attn_out.mean(-1)[mask].sort(descending=True)"
   ],
   "id": "3d90e77e6c65f945",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#overall_influence_copy = torch.clone(overall_influence)\n",
    "left_aggr_copy = torch.clone(left_aggr)"
   ],
   "id": "b241a99650ab8abb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Let's assume 'final_model' and 'batch_data' are defined as in your example.\n",
    "# batch_data.x is assumed to have shape [49, F]\n",
    "\n",
    "# --- Step 1: Get reference output from the full model ---\n",
    "with torch.inference_mode():\n",
    "    final_model.eval()\n",
    "    # model_logits will have shape [49, 1]\n",
    "    model_logits, (edge_index_attn, alpha) = final_model(batch_data.x, batch_data.edge_index)\n",
    "\n",
    "# --- Step 2: Manually reproduce the forward pass on the FULL graph ---\n",
    "with torch.inference_mode():\n",
    "    final_model.eval()\n",
    "    # Weight extraction is correct\n",
    "    w_l = final_model.state_dict()[\"conv1.lin_l.weight\"]\n",
    "    w_r = final_model.state_dict()[\"conv1.lin_r.weight\"]\n",
    "    rlt = final_model.state_dict()[\"conv2.lin.weight\"]\n",
    "    bl = final_model.state_dict()['conv1.lin_l.bias']\n",
    "    b2 = final_model.state_dict()['conv2.bias']\n",
    "\n",
    "    all_nodes = batch_data.x\n",
    "    num_nodes = all_nodes.shape[0]  # This will now be 49\n",
    "\n",
    "    left_aggr = torch.zeros_like(all_nodes)\n",
    "    \n",
    "    lifted_nodes = torch.index_select(all_nodes, 0, batch_data.edge_index[0, ~mask])\n",
    "    \n",
    "    index_for_sage = batch_data.edge_index[1, ~mask].repeat(batch_data.x.shape[-1], 1).t()\n",
    "    left_aggr.scatter_reduce_(0, index_for_sage, lifted_nodes, reduce=\"sum\", include_self=False)\n",
    "\n",
    "    overall_influence = (all_nodes @ w_r.t()) + (left_aggr @ w_l.t()  + bl)\n",
    "    x_transformed = overall_influence @ rlt.t()\n",
    "\n",
    "    source_node_indices = edge_index_attn[0]\n",
    "    target_node_indices = edge_index_attn[1]\n",
    "    \n",
    "    source_features_transformed = x_transformed[source_node_indices]\n",
    "    weighted_messages = source_features_transformed * alpha\n",
    "    aggregated_output = torch.zeros(num_nodes, rlt.shape[0], device=all_nodes.device)\n",
    "    index_for_gat = target_node_indices.unsqueeze(1).expand_as(weighted_messages)\n",
    "    aggregated_output.scatter_add_(0, index_for_gat, weighted_messages)\n",
    "    \n",
    "    manual_logits = aggregated_output.mean(dim=1, keepdim=True) + b2\n",
    "\n",
    "    print(\"Manual logits match model logits:\", torch.allclose(manual_logits, model_logits))\n",
    "    print(\"Max Difference:\", (manual_logits - model_logits).abs().max()) "
   ],
   "id": "43375993799b2b8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_logits",
   "id": "6ea6feed6562d8c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_model = final_model.to('cuda')",
   "id": "a9badcb80e84bb09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# --- 1. SET UP THE DEVICE ---\n",
    "# This is the most important step. Define the device to use.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# --- 2. MOVE MODEL AND DATA TO THE DEVICE ---\n",
    "# Let's assume 'final_model' and 'batch_data' are loaded and are on the CPU initially.\n",
    "\n",
    "final_model.to(device)\n",
    "final_model.eval() # Set to evaluation mode\n",
    "\n",
    "# This is the crucial fix: move the entire data batch to the selected device.\n",
    "batch_data = batch_data.to(device)\n",
    "\n",
    "\n",
    "# Now, all tensors involved in the calculation will be on the same device.\n",
    "with torch.inference_mode():\n",
    "    # --- Step 1: Get reference output from the full model ---\n",
    "    # This will now run entirely on the specified `device`.\n",
    "    model_logits, (edge_index_attn, alpha) = final_model(batch_data.x, batch_data.edge_index)\n",
    "\n",
    "    # --- Step 2: Extract weights (they are already on the correct device) ---\n",
    "    state_dict = final_model.state_dict()\n",
    "    w_l = state_dict[\"conv1.lin_l.weight\"]\n",
    "    w_r = state_dict[\"conv1.lin_r.weight\"]\n",
    "    rlt = state_dict[\"conv2.lin.weight\"]\n",
    "    bl = state_dict['conv1.lin_l.bias']\n",
    "    b2 = state_dict['conv2.bias']\n",
    "\n",
    "    # --- Step 3: Manual SAGEConv Layer ---\n",
    "    # `all_nodes` is now on the correct device because `batch_data` was moved.\n",
    "    all_nodes = batch_data.x \n",
    "    num_nodes = all_nodes.shape[0]\n",
    "\n",
    "    # `zeros_like` will create a tensor on the same device as `all_nodes`.\n",
    "    left_aggr = torch.zeros_like(all_nodes)\n",
    "    \n",
    "    lifted_nodes = torch.index_select(all_nodes, 0, batch_data.edge_index[0, ~mask])\n",
    "    \n",
    "    index_for_sage = batch_data.edge_index[1, ~mask].unsqueeze(1).expand_as(lifted_nodes)\n",
    "    left_aggr.scatter_reduce_(0, index_for_sage, lifted_nodes, reduce=\"sum\", include_self=False)\n",
    "\n",
    "    # This matrix multiplication will now work, as all tensors are on the same device.\n",
    "    overall_influence = (all_nodes @ w_r.t()) + (left_aggr @ w_l.t()) + bl\n",
    "    \n",
    "    # --- Step 4: Direct GATConv Calculation for the Readout Node ---\n",
    "    x_transformed = overall_influence @ rlt.t()\n",
    "\n",
    "    readout_node_idx = num_nodes - 1\n",
    "    is_edge_to_readout = (edge_index_attn[1] == readout_node_idx)\n",
    "    \n",
    "    source_nodes_for_readout = edge_index_attn[0][is_edge_to_readout]\n",
    "    attention_for_readout = alpha[is_edge_to_readout]\n",
    "\n",
    "    source_features = x_transformed[source_nodes_for_readout]\n",
    "    \n",
    "    weighted_messages = source_features * attention_for_readout\n",
    "    aggregated_message = weighted_messages.sum(dim=0)\n",
    "\n",
    "    manual_readout_logit = aggregated_message.mean() + b2\n",
    "\n",
    "    # --- Verification ---\n",
    "    final_model_logit = model_logits[-1]\n",
    "    \n",
    "    print(f\"Manual Readout Logit: {manual_readout_logit.item()}\")\n",
    "    print(f\"Model Readout Logit:    {final_model_logit.item()}\")\n",
    "    print(\"Logits Match:\", torch.allclose(manual_readout_logit, final_model_logit))"
   ],
   "id": "ed948c951da6c356",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.allclose(x_transformed[:-1].mean(-1), sage_out_transformed)",
   "id": "e198aa8238423297",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "35e52c385e7021d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.allclose(left_aggr @ w_l.t(), left_aggr * w_l.squeeze())",
   "id": "bd9ab77d26c147c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "manual_logits[-1], model_logits[-1]",
   "id": "20ccd822ffc6a4a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "weighted_messages.mean(-1)[mask].sum(), model_logits",
   "id": "52062f735e1717b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.inference_mode():\n",
    "    final_model.eval()\n",
    "    logits = final_model(batch_data.x, batch_data.edge_index)\n",
    "logits[0]"
   ],
   "id": "f984aa3772bc1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "((overall_influence.scatter_reduce(0, batch_data.edge_index[1, ~mask].cpu(), lifted_neighbor_influence, reduce=\"sum\").cpu() * rlt[:].mean(0).cpu()) * attn_out[mask, :].mean(-1).cpu()).sum() ",
   "id": "b7fac72171bdff9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch_data.edge_index",
   "id": "3dbb3da414a391ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "attn_out[mask, :].cpu().shape",
   "id": "6b978d0f5d0a16fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch_data.x[:-1].nonzero() @ w_r.squeeze() * rlt[:].mean() * attn_out[mask, :].mean(-1)",
   "id": "171e9c82ac5c0934",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch_data.x[:-1].nonzero()",
   "id": "31f5723c9f7ada52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# ## Overall  Self influence\n",
    "# font = {'family' : 'arial',\n",
    "#         'weight' : 'bold',\n",
    "#         'size'   : 14}\n",
    "# \n",
    "# matplotlib.rc('font', **font)\n",
    "# plt.figure(figsize=(25, 4))\n",
    "attn_identity_matrix = torch.zeros_like(batch_data.x[:-1].cpu()).cpu()\n",
    "indices = batch_data.x[:-1].nonzero().cpu()\n",
    "attn_identity_matrix[indices[:, 0], indices[:, 1]] = 1\n",
    "attn_identity_matrix = attn_identity_matrix.to(device)\n",
    "## TODO: Need to get global influence from here\n",
    "\n",
    "self_influence = (attn_identity_matrix @ w_r.squeeze() * rlt[:].mean() * attn_out[mask, :].mean(-1)).cpu()\n",
    "\n",
    "# plt.bar(batch_data.entities_list, self_influence)\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.title(\"Overall Self influence\")\n",
    "# plt.xlabel(\"Entities\")\n",
    "# plt.ylabel(\"Influence weight on prediction\")\n",
    "# plt.grid(which=\"both\")\n",
    "# plt.show()"
   ],
   "id": "ae9b1a89cdcf39fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch_data.x[:-1].nonzero().cpu()",
   "id": "eef780ab359b6a3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "attn_identity_matrix.shape",
   "id": "28e6eff3161c4167",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "attn_identity_matrix",
   "id": "fc9b6dd3b69f65eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "non_zero_idx = batch_data.x.nonzero() #w_r.squeeze() * rlt[:].mean() * attn_out[mask, :].mean(-1)\n",
    "torch.index_select(attn_out[mask], 0, non_zero_idx[:, 0])"
   ],
   "id": "aa8cdf624ed1b970",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stacked_gcn_influence = torch.cat((final_model.state_dict()[\"conv1.lin_l.weight\"], final_model.state_dict()[\"conv1.lin_r.weight\"]), dim = 0).transpose(-1, 0)\n",
    "stacked_gcn_influence.mean(1), stacked_gcn_influence.std(1)"
   ],
   "id": "4e505489bb38d051",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "(vectorizer.get_feature_names_out().shape, final_model.state_dict()[\"conv1.lin_r.weight\"].shape)",
   "id": "f16ce023e22a0642",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_model.state_dict()[\"conv1.lin_r.weight\"].squeeze()",
   "id": "ab602c2348dd6889",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2f975330bc75f8f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "top_n = 50\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "sort_idx = final_model.state_dict()[\"conv1.lin_r.weight\"].squeeze().abs().argsort(descending=True).cpu()\n",
    "plt.bar(vectorizer.get_feature_names_out()[sort_idx][:top_n], final_model.state_dict()[\"conv1.lin_r.weight\"].squeeze()[sort_idx][:top_n].cpu())\n"
   ],
   "id": "6d6af6c9e0e21d50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Least important\n",
    "vectorizer.get_feature_names_out()[sort_idx][-top_n:]"
   ],
   "id": "357df4574e444a78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_model.state_dict()",
   "id": "1dcde5f6086f30cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sepsis_attn_outs, control_attn_outs = [], []\n",
    "sepsis_entities, control_entities = [], []\n",
    "for i, batch_data in enumerate(train_graphs):\n",
    "    batch_data = batch_data.to(device)\n",
    "    with torch.inference_mode():\n",
    "        final_model.eval()\n",
    "        logits, (edge_idx, attn_out) = final_model(batch_data.x,batch_data.edge_index)\n",
    "        # logits = torch.sigmoid(logits[-1])\n",
    "    mask = edge_idx[1] == (batch_data.x.shape[0]-1)\n",
    "    assert attn_out[mask].shape[0] == len(batch_data.entities_list), \"Doesnt match entities\"\n",
    "    assert (torch.sort(edge_idx[0][mask])[0] != edge_idx[0][mask]).sum() == 0, \"Is not sorted\"\n",
    "    if batch_data.y[0] == 1:\n",
    "        sepsis_entities.extend(batch_data.entities_list)\n",
    "        print(batch_data.entities_list)\n",
    "        print(batch_data.x.nonzero())\n",
    "        raise Exception(\"\")\n",
    "        sepsis_attn_outs.append(attn_out[mask])\n",
    "    if batch_data.y[0] == 0:\n",
    "        control_entities.extend(batch_data.entities_list)\n",
    "        control_attn_outs.append(attn_out[mask])\n",
    "    # if i == 2:\n",
    "    #     break\n",
    "sepsis_attn_outs = torch.cat(sepsis_attn_outs, dim  = 0)\n",
    "control_attn_outs = torch.cat(control_attn_outs, dim  = 0)"
   ],
   "id": "60c9c5a076f922",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "vectorizer.transform([\"IDDM with periperal neuropathy\"]).toarray().nonzero()",
   "id": "b3613746c6fb6aec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from operator import itemgetter\n",
    "print(itemgetter(*[2482, 3900, 5143, 5733, 8203])(vectorizer.get_feature_names_out()))\n"
   ],
   "id": "28120ea2efeeef2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ecc5cdf8d241589a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "sepsis_attn_df = pd.DataFrame()\n",
    "sepsis_attn_df[\"entities\"] = sepsis_entities\n",
    "sepsis_attn_df[\"attn_out_0\"] = sepsis_attn_outs[:, 0].cpu()\n",
    "sepsis_attn_df[\"attn_out_1\"] = sepsis_attn_outs[:, 1].cpu()\n",
    "sepsis_attn_df[\"attn_out_mean\"] = sepsis_attn_outs.mean(-1).cpu()\n",
    "sepsis_attn_df.sort_values(by=[\"attn_out_mean\"], ascending=False, inplace=True)\n",
    "sepsis_attn_df"
   ],
   "id": "daeb187451ca6c8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "control_attn_df = pd.DataFrame()\n",
    "control_attn_df[\"entities\"] = control_entities\n",
    "control_attn_df[\"attn_out_0\"] = control_attn_outs[:, 0].cpu()\n",
    "control_attn_df[\"attn_out_1\"] = control_attn_outs[:, 1].cpu()\n",
    "control_attn_df[\"attn_out_mean\"] = control_attn_outs.mean(-1).cpu()\n",
    "control_attn_df.sort_values(by=[\"attn_out_mean\"], ascending=False, inplace=True)\n",
    "control_attn_df"
   ],
   "id": "71f83c0236f36ea0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.concat((control_attn_df, sepsis_attn_df) , axis = 0)",
   "id": "11a2c231d2f248de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(sepsis_attn_df.iloc[:20, :])",
   "id": "4ce665572a3c6080",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = train_graphs[80].to(device)\n",
    "with torch.inference_mode():\n",
    "    final_model.eval()\n",
    "    logits, (edge_idx, attn_out) = final_model(data.x,data.edge_index)\n",
    "    logits = torch.sigmoid(logits[-1])\n",
    "attn_out.shape"
   ],
   "id": "af993a80e7e2b1d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "edge_idx",
   "id": "50ca2312f086868c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from typing import List\n",
    "import math\n",
    "\n",
    "def plot_graph(\n",
    "    edge_index: torch.Tensor,\n",
    "    node_labels: List[str],\n",
    "    edge_weights: torch.Tensor,\n",
    "    node_size: int = 2000,\n",
    "    node_color: str = 'skyblue',\n",
    "    central_node_color: str = 'lightcoral',\n",
    "    font_size: int = 12,\n",
    "    font_color: str = 'black',\n",
    "    edge_width: float = 2.0,\n",
    "    figure_size: tuple = (12, 12)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a graph with a custom layout where the last node is central.\n",
    "    Node distance is based on the inverse of edge weight to the central node.\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): A tensor of shape (2, E) representing the edges in COO format.\n",
    "        node_labels (List[str]): A list of N strings for node labels.\n",
    "        edge_weights (torch.Tensor): A tensor of shape (1, E) or (E,) with edge weights between 0 and 1.\n",
    "        node_size (int): The size of the nodes.\n",
    "        node_color (str): The color of the non-central nodes.\n",
    "        central_node_color (str): The color of the central node.\n",
    "        font_size (int): The font size of the node labels.\n",
    "        font_color (str): The color of the node labels.\n",
    "        edge_width (float): The width of the edges.\n",
    "        figure_size (tuple): The size of the plot figure.\n",
    "    \"\"\"\n",
    "    # --- Graph and Data Preparation ---\n",
    "    graph = nx.Graph()\n",
    "    num_nodes = len(node_labels)\n",
    "    graph.add_nodes_from(range(num_nodes))\n",
    "    labels = {i: label for i, label in enumerate(node_labels)}\n",
    "    edge_list = edge_index.t().tolist()\n",
    "    weights_list = edge_weights.squeeze().tolist()\n",
    "    \n",
    "    # Create a lookup dictionary for edge weights for efficient access\n",
    "    edge_to_weight = {tuple(sorted(edge)): weight for edge, weight in zip(edge_list, weights_list)}\n",
    "\n",
    "    # --- Custom Layout Calculation ---\n",
    "    pos = {}\n",
    "    central_node_idx = num_nodes - 1\n",
    "    other_node_indices = [i for i in range(num_nodes) if i != central_node_idx]\n",
    "    \n",
    "    # Place central node at the origin\n",
    "    pos[central_node_idx] = (0, 0)\n",
    "    \n",
    "    # Arrange other nodes in a circle around the central node\n",
    "    angle_step = 2 * math.pi / len(other_node_indices)\n",
    "    max_radius = 1.0 # Base radius for layout scaling\n",
    "    \n",
    "    for i, node_idx in enumerate(other_node_indices):\n",
    "        weight = edge_to_weight.get(tuple(sorted((node_idx, central_node_idx))))\n",
    "        \n",
    "        # Distance is inversely proportional to weight. Add a small constant to avoid zero distance.\n",
    "        # If no edge exists, place it at the maximum distance.\n",
    "        radius = max_radius * (1.1 - weight) if weight is not None else max_radius * 1.2\n",
    "        \n",
    "        angle = i * angle_step\n",
    "        pos[node_idx] = (radius * math.cos(angle), radius * math.sin(angle))\n",
    "\n",
    "    # --- Plotting ---\n",
    "    fig, ax = plt.subplots(figsize=figure_size)\n",
    "    custom_cmap = LinearSegmentedColormap.from_list('blue_purple_red', ['blue', 'purple', 'red'])\n",
    "\n",
    "    # Assign colors to nodes\n",
    "    node_colors = [central_node_color if i == central_node_idx else node_color for i in range(num_nodes)]\n",
    "\n",
    "    # Draw nodes and labels\n",
    "    nx.draw_networkx_nodes(graph, pos, node_size=node_size, node_color=node_colors, ax=ax)\n",
    "    nx.draw_networkx_labels(graph, pos, labels, font_size=font_size, font_color=font_color, ax=ax)\n",
    "    \n",
    "    # Draw edges with heatmap\n",
    "    edges = nx.draw_networkx_edges(\n",
    "        graph,\n",
    "        pos,\n",
    "        edgelist=edge_list,\n",
    "        edge_color=weights_list,\n",
    "        edge_cmap=custom_cmap,\n",
    "        width=edge_width,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Add a colorbar for edge weights\n",
    "    sm = plt.cm.ScalarMappable(cmap=custom_cmap, norm=plt.Normalize(vmin=0, vmax=1))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, shrink=0.8)\n",
    "    cbar.set_label('Edge Weight', rotation=270, labelpad=15)\n",
    "    \n",
    "    ax.set_title(\"Graph with Central Node Layout\")\n",
    "    ax.axis('equal') # Ensure the circular layout is not distorted\n",
    "    ax.margins(0.1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "data = test_graphs[80].to(device)\n",
    "with torch.inference_mode():\n",
    "    final_model.eval()\n",
    "    logits, (edge_idx, attn_out) = final_model(data.x,data.edge_index)\n",
    "    logits = torch.sigmoid(logits[-1])\n",
    "    print(logits)\n",
    "# Define the graph data\n",
    "edge_index_tensor = data.edge_index\n",
    "node_names = [*data.entities_list, \"Read-Out\"]\n",
    "edge_weights_tensor = attn_out.mean(-1)\n",
    "\n",
    "# Plot the graph\n",
    "plot_graph(\n",
    "    edge_index=edge_index_tensor,\n",
    "    node_labels=node_names,\n",
    "    edge_weights=edge_weights_tensor\n",
    ")"
   ],
   "id": "fb511ab6ea3d7092",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "readout_mask = edge_index_tensor[1] == (data.x.shape[0]-1)\n",
    "\n",
    "data.entities_list[edge_index_tensor[0, readout_mask][2]]"
   ],
   "id": "7cd85f1296fd015a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_model.state_dict()",
   "id": "191af7e76073f4a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "edge_index_tensor[:, readout_mask]",
   "id": "c76ddfc1cb8c1f66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "edge_weights_tensor[readout_mask]",
   "id": "f2eed1e9f2372eef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sorted_weights_idx = torch.argsort(edge_weights_tensor[readout_mask], descending=True)",
   "id": "c6671ac689a4e4a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from operator import itemgetter\n",
    "print(itemgetter(*sorted_weights_idx)(data.entities_list))"
   ],
   "id": "51e2b28cef940f2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(itemgetter(*sorted_weights_idx)(edge_weights_tensor[readout_mask]))",
   "id": "4edee245b6db169b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "edge_index_tensor[:, readout_mask][0, sorted_weights_idx]",
   "id": "1582ad8cff8f2002",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.x[7][data.x[7].nonzero().squeeze()]",
   "id": "e1024c3962ef0b64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_model.state_dict()",
   "id": "7253ec5a91ff7ced",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tf_idf_weights = final_model.state_dict()['conv1.lin_r.weight']\n",
    "tf_idf_weights_l = final_model.state_dict()['conv1.lin_l.weight']\n",
    "#[data.x[7].nonzero().squeeze().cpu()]"
   ],
   "id": "8478d6a5158eae3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sorted_w_l_idx = tf_idf_weights_l.abs().argsort(descending = True).cpu()\n",
    "vectorizer.get_feature_names_out()[sorted_w_l_idx][0, :50]"
   ],
   "id": "57a30ff13f144cdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "data.x @ tf_idf_weights_l.squeeze()"
   ],
   "id": "d5e9727e0fe84d59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.x @ tf_idf_weights.squeeze()",
   "id": "cbea0328e420febf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "[data.x[7].nonzero().squeeze().cpu()]",
   "id": "b817d97b694b6d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tf_idf_weights.squeeze()[data.x[7].nonzero().squeeze().cpu()]",
   "id": "c5d246cb6005907",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "raise Exception(\"\")",
   "id": "401a62f8c4bf7316",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "vectorizer.get_feature_names_out()[data.x[7].nonzero().squeeze().cpu()]",
   "id": "58618ef325c28f79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "read_out_mask = edge_idx[1] == data.x.shape[0]-1\n",
    "attn_out[read_out_mask].mean(1)"
   ],
   "id": "88c7112383bcae49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_model.state_dict()",
   "id": "ac0498ca91a4237f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "## TODO Edge attr with edge attr TfIDF vectorizer",
   "id": "ae308f5c899242d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "final_model.eval()\n",
    "final_model = final_model.to(device)\n",
    "# Assume 'data' is your graph data object (e.g., from a PyG dataset)\n",
    "data = test_graphs[0]\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=final_model,\n",
    "    algorithm=GNNExplainer(epochs=10),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='node',\n",
    "        return_type='raw',\n",
    "    ),\n",
    ")\n",
    "node_index = -1 # which node index to explain\n",
    "explanation = explainer(data.x, data.edge_index, index=node_index)"
   ],
   "id": "7176c83202a93091",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "explanation.visualize_feature_importance(top_k=5)",
   "id": "2b9829793d793201",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
